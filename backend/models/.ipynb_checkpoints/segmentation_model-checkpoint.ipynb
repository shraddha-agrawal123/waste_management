{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9216acf2-4eb3-4de3-bfc3-4916f1cdc569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae8cd1ac-591a-497e-93e3-65defce9326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = r\"C:\\Users\\shrad\\mini_project\\ai-waste-project\\backend\\datasets\\waste-images\"\n",
    "soil_csv_path = r\"C:\\Users\\shrad\\mini_project\\ai-waste-project\\backend\\datasets\\soil_nutrient.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88459869-7c54-4c54-ab5a-29ee8613c809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soil mapping keys: ['Chalky Soil', 'Chalky Soil  ', 'Clay Soil', 'Clay Soil  ', 'Loamy Soil', 'Loamy Soil  ', 'Peaty Soil', 'Peaty Soil  ', 'Saline Soil', 'Saline Soil  ', 'Sandy Soil', 'Sandy Soil  ', 'Silt Soil', 'Silt Soil  ']\n"
     ]
    }
   ],
   "source": [
    "soil_data = pd.read_csv(soil_csv_path)\n",
    "soil_data.columns = soil_data.columns.str.strip()  # Remove spaces in column names\n",
    "\n",
    "if \"Soil_Type\" not in soil_data.columns:\n",
    "    raise KeyError(\"Column 'Soil_Type' is missing! Available columns:\", soil_data.columns)\n",
    "\n",
    "# Ensure unique Soil Types (group by average values)\n",
    "soil_data = soil_data.groupby(\"Soil_Type\").mean().reset_index()\n",
    "\n",
    "# Create soil mapping for lookup\n",
    "soil_mapping = soil_data.set_index(\"Soil_Type\").to_dict(orient=\"index\")\n",
    "\n",
    "# Print soil mapping keys\n",
    "print(\"Soil mapping keys:\", list(soil_mapping.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0cb0c5a-7d9b-44f5-be05-ce84f525b10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WasteDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, image_dir, soil_mapping, batch_size=32, img_size=(224, 224), shuffle=True):\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.soil_mapping = soil_mapping  # Store soil nutrient mapping\n",
    "        \n",
    "        self.image_files = []\n",
    "        self.class_indices = {}  # Map class names to indices\n",
    "        class_id = 0\n",
    "\n",
    "        for category in os.listdir(image_dir):  \n",
    "            category_path = os.path.join(image_dir, category)\n",
    "            if os.path.isdir(category_path):\n",
    "                if category not in self.class_indices:\n",
    "                    self.class_indices[category] = class_id\n",
    "                    class_id += 1\n",
    "                for file in os.listdir(category_path):\n",
    "                    if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        self.image_files.append((os.path.join(category_path, file), category))  # Store full path & class\n",
    "        \n",
    "        self.num_classes = len(self.class_indices)  # Total number of waste categories\n",
    "        self.on_epoch_end()  # Shuffle data at initialization\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.image_files) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_files = self.image_files[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_images, batch_soil_features, batch_labels = [], [], []\n",
    "\n",
    "        for file_path, category in batch_files:\n",
    "            img = self.load_and_segment_image(file_path)  \n",
    "            if img is None:\n",
    "                continue  # Skip if image failed to load\n",
    "\n",
    "            parts = os.path.basename(file_path).split(\"_\")\n",
    "            if len(parts) < 2:\n",
    "                continue  # Skip incorrect format files\n",
    "            soil_type = parts[0]\n",
    "\n",
    "            label = np.zeros(self.num_classes)\n",
    "            label[self.class_indices[category]] = 1  \n",
    "\n",
    "            # Ensure all 7 nutrient features are extracted\n",
    "            soil_features = self.soil_mapping.get(soil_type, np.zeros(7))  \n",
    "            soil_features = list(soil_features.values())  # Convert dict values to list\n",
    "            \n",
    "            batch_images.append(img)\n",
    "            batch_soil_features.append(soil_features)\n",
    "            batch_labels.append(label)\n",
    "\n",
    "        # Ensure at least one sample exists in the batch\n",
    "        if len(batch_images) == 0:\n",
    "            return (\n",
    "                (np.zeros((self.batch_size, *self.img_size, 3)), np.zeros((self.batch_size, 7))), \n",
    "                (np.zeros((self.batch_size, self.num_classes)), np.zeros((self.batch_size, 7)))\n",
    "            )\n",
    "\n",
    "        # Convert to TensorFlow tensors\n",
    "        batch_images = tf.convert_to_tensor(batch_images, dtype=tf.float32)\n",
    "        batch_soil_features = tf.convert_to_tensor(batch_soil_features, dtype=tf.float32)\n",
    "        batch_labels = tf.convert_to_tensor(batch_labels, dtype=tf.float32)\n",
    "        nutrient_outputs = tf.zeros((len(batch_labels), 7), dtype=tf.float32)  # Ensure 7 nutrient features\n",
    "\n",
    "        # Return inputs and outputs as tuples\n",
    "        return (\n",
    "            (batch_images, batch_soil_features), \n",
    "            (batch_labels, nutrient_outputs)\n",
    "        )\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.image_files)\n",
    "\n",
    "    def load_and_segment_image(self, img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"❌ Failed to load image: {img_path}\")\n",
    "            return None\n",
    "        img = cv2.resize(img, self.img_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        _, segmented = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "        img[segmented == 0] = 0  \n",
    "        \n",
    "        return img / 255.0  # Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b7f6e7-dff5-456a-ba47-70736d9716af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrad\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 3s/step - loss: 0.0000e+00 - nutrient_levels_loss: 0.0000e+00 - nutrient_levels_mae: 0.0000e+00 - waste_class_accuracy: 0.1328 - waste_class_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_nutrient_levels_loss: 0.0000e+00 - val_nutrient_levels_mae: 0.0000e+00 - val_waste_class_accuracy: 0.0000e+00 - val_waste_class_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 3s/step - loss: 0.0000e+00 - nutrient_levels_loss: 0.0000e+00 - nutrient_levels_mae: 0.0000e+00 - waste_class_accuracy: 0.0901 - waste_class_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_nutrient_levels_loss: 0.0000e+00 - val_nutrient_levels_mae: 0.0000e+00 - val_waste_class_accuracy: 0.0000e+00 - val_waste_class_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3s/step - loss: 0.0000e+00 - nutrient_levels_loss: 0.0000e+00 - nutrient_levels_mae: 0.0000e+00 - waste_class_accuracy: 0.1504 - waste_class_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_nutrient_levels_loss: 0.0000e+00 - val_nutrient_levels_mae: 0.0000e+00 - val_waste_class_accuracy: 1.0000 - val_waste_class_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - loss: 0.0000e+00 - nutrient_levels_loss: 0.0000e+00 - nutrient_levels_mae: 0.0000e+00 - waste_class_accuracy: 0.1629 - waste_class_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_nutrient_levels_loss: 0.0000e+00 - val_nutrient_levels_mae: 0.0000e+00 - val_waste_class_accuracy: 0.0000e+00 - val_waste_class_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 3s/step - loss: 0.0000e+00 - nutrient_levels_loss: 0.0000e+00 - nutrient_levels_mae: 0.0000e+00 - waste_class_accuracy: 0.1878 - waste_class_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_nutrient_levels_loss: 0.0000e+00 - val_nutrient_levels_mae: 0.0000e+00 - val_waste_class_accuracy: 0.0000e+00 - val_waste_class_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3s/step - loss: 0.0000e+00 - nutrient_levels_loss: 0.0000e+00 - nutrient_levels_mae: 0.0000e+00 - waste_class_accuracy: 0.1748 - waste_class_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_nutrient_levels_loss: 0.0000e+00 - val_nutrient_levels_mae: 0.0000e+00 - val_waste_class_accuracy: 0.0000e+00 - val_waste_class_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m696s\u001b[0m 9s/step - loss: 0.0000e+00 - nutrient_levels_loss: 0.0000e+00 - nutrient_levels_mae: 0.0000e+00 - waste_class_accuracy: 0.1575 - waste_class_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_nutrient_levels_loss: 0.0000e+00 - val_nutrient_levels_mae: 0.0000e+00 - val_waste_class_accuracy: 0.0000e+00 - val_waste_class_loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 4s/step - loss: 0.0000e+00 - nutrient_levels_loss: 0.0000e+00 - nutrient_levels_mae: 0.0000e+00 - waste_class_accuracy: 0.1525 - waste_class_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_nutrient_levels_loss: 0.0000e+00 - val_nutrient_levels_mae: 0.0000e+00 - val_waste_class_accuracy: 0.0000e+00 - val_waste_class_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m954s\u001b[0m 12s/step - loss: 0.0000e+00 - nutrient_levels_loss: 0.0000e+00 - nutrient_levels_mae: 0.0000e+00 - waste_class_accuracy: 0.1961 - waste_class_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_nutrient_levels_loss: 0.0000e+00 - val_nutrient_levels_mae: 0.0000e+00 - val_waste_class_accuracy: 0.0000e+00 - val_waste_class_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 7s/step - loss: 0.0000e+00 - nutrient_levels_loss: 0.0000e+00 - nutrient_levels_mae: 0.0000e+00 - waste_class_accuracy: 0.1602 - waste_class_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_nutrient_levels_loss: 0.0000e+00 - val_nutrient_levels_mae: 0.0000e+00 - val_waste_class_accuracy: 0.0000e+00 - val_waste_class_loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model training complete and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Generators\n",
    "image_dir = r\"C:\\Users\\shrad\\Downloads\\waste-images\\dataset-resized\"\n",
    "soil_mapping = { \"Clay\": {\"Zinc(%)\": 0.3, \"Copper(%)\": 0.5, \"Iron(%)\": 0.2, \"Nitrogen(%)\": 0.1}, \n",
    "                \"Sandy\": {\"Zinc(%)\": 0.2, \"Copper(%)\": 0.4, \"Iron(%)\": 0.3, \"Nitrogen(%)\": 0.2}}  # Example mapping\n",
    "\n",
    "batch_size = 32\n",
    "train_generator = WasteDataGenerator(image_dir, soil_mapping, batch_size=batch_size, shuffle=True)\n",
    "val_generator = WasteDataGenerator(image_dir, soil_mapping, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define Model\n",
    "image_input = Input(shape=(224, 224, 3), name=\"image_input\")\n",
    "soil_input = Input(shape=(7,), name=\"soil_input\")  # Updated to 7 nutrient features\n",
    "\n",
    "# MobileNetV2 as base model\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "x = GlobalAveragePooling2D()(base_model(image_input))\n",
    "\n",
    "# Waste Classification Branch\n",
    "x_class = Dense(1024, activation=\"relu\")(x)\n",
    "waste_class_output = Dense(train_generator.num_classes, activation=\"softmax\", name=\"waste_class\")(x_class)\n",
    "\n",
    "# Nutrient Level Prediction Branch\n",
    "x_nutrient = Dense(256, activation=\"relu\")(soil_input)\n",
    "x_nutrient = Dense(128, activation=\"relu\")(x_nutrient)\n",
    "x_nutrient = Dense(64, activation=\"relu\")(x_nutrient)\n",
    "nutrient_output = Dense(7, activation=\"linear\", name=\"nutrient_levels\")(x_nutrient)  # Updated to 7 nutrient features\n",
    "\n",
    "# Build Model\n",
    "model = Model(inputs=[image_input, soil_input], outputs=[waste_class_output, nutrient_output])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss={\"waste_class\": \"categorical_crossentropy\", \"nutrient_levels\": \"mse\"},\n",
    "              metrics={\"waste_class\": \"accuracy\", \"nutrient_levels\": \"mae\"})\n",
    "\n",
    "# Train Model\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=10)\n",
    "\n",
    "# Save trained model\n",
    "model.save('backend/models/trashnet_mobilenetv2_nutrients.h5', save_format='h5')\n",
    "print(\"✅ Model training complete and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f089813-f129-41db-97b7-b5f8f23822b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e224823b-8227-418d-809d-9253204c2064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf19a189-406a-4dde-a867-ef8faabf578a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab8fc4a-5582-4382-82c7-5a70d396ac46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
